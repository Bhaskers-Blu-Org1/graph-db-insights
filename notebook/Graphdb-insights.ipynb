{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A guide on how to use Orientdb!\n",
    "This notebook demonstrate on how to use pyorient- a python driver for orientdb to communicate with the orientdb.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some points to be noted!\n",
    "* Before setting up this notebook, set up orientdb on kubernetes.\n",
    "\n",
    "* To set up the orientdb on kubernetes, follow this developer journey : https://github.com/IBM/deploy-graph-db-container.\n",
    "\n",
    "* The notebook makes use of a config.json file which include all the details about the database you want to create on orientdb like username, password of the orientdb, and the schema for your database.\n",
    "\n",
    "* Its recommended to set the same username and password for databases that you have set for the orientdb for the ease.In the yaml file for creating the orientdb service on kubernetes, the username and the password used is root and  rootpwd. However, user can change it as per their choice in yaml file and the config file.\n",
    "\n",
    "* The dataset consumed by this notebook is kaggle imdb movie dataset, you can download it from https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset.\n",
    "\n",
    "* For the purpose of this tutorial, data has been trimmed to 600 rows and named it as `graphdb-insights.csv`.\n",
    "\n",
    "* This notebook gives hands on how to perform various operations on orientdb through python.\n",
    "\n",
    "* Orientdb also provides an interactive orientdb studio to create new graph database, create schema, add, delete, and update records.You can watch this video tutorial https://www.youtube.com/watch?v=l-OVSjf-vk0&feature=youtu.be to know the working of orientdb.You can follow the documentation(readme file) of this project which give a comprehensive tutorial on how to use orientdb console. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the pyorient package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyorient in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s830-1b9eba6f1e7ba3-8983456f5308/.local/lib/python2.7/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "######## download pyorientdb \n",
    "! pip install pyorient --user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyorient, json, pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add your service credentials for Object Storage\n",
    "* You must create Object Storage service on Bluemix. To access data in a file in Object Storage, you need the Object Storage authentication credentials. Click on insert to code for the file you want to use in the code.\n",
    "* For config.json file, click on insert to code dropdown and choose `insert credentials`.\n",
    "* For movie dataset ( graphdb-insights.csv ), click on insert to code dropdown and choose `Insert Pandas Dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # @hidden_cell\n",
    "credentials_1 = {\n",
    "  'auth_url':'https://identity.open.softlayer.com',\n",
    "  'project':'object_storage_3fd48083_3bbd_4355_a296_f2558dc1b897',\n",
    "  'project_id':'07704599ed444df0927832e455d9ec63',\n",
    "  'region':'dallas',\n",
    "  'user_id':'fb16c3d0955c42538faa723269123f5d',\n",
    "  'domain_id':'1bfd0aa070764f39845124cf77d75a19',\n",
    "  'domain_name':'1104675',\n",
    "  'username':'member_b6c199f708035093454e23f2785a418ef096423b',\n",
    "  'password':\"\"\"VO~S.?)5E6g2!!Dh\"\"\",\n",
    "  'container':'graphdb',\n",
    "  'tenantId':'undefined',\n",
    "  'filename':'config.json'\n",
    "}\n",
    "\n",
    "from io import BytesIO  \n",
    "import requests  \n",
    "import json  \n",
    "import pandas as pd\n",
    "\n",
    "# loading the config.json\n",
    "\n",
    "def get_data(credentials):  \n",
    "    \"\"\"This functions returns a StringIO object containing\n",
    "    the file content from Bluemix Object Storage V3.\"\"\"\n",
    "\n",
    "    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n",
    "    data = {'auth': {'identity': {'methods': ['password'],\n",
    "            'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']},\n",
    "            'password': credentials['password']}}}}}\n",
    "    headers1 = {'Content-Type': 'application/json'}\n",
    "    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n",
    "    resp1_body = resp1.json()\n",
    "    for e1 in resp1_body['token']['catalog']:\n",
    "        if(e1['type']=='object-store'):\n",
    "            for e2 in e1['endpoints']:\n",
    "                        if(e2['interface']=='public'and e2['region']=='dallas'):\n",
    "                            url2 = ''.join([e2['url'],'/', credentials['container'], '/', credentials['filename']])\n",
    "    s_subject_token = resp1.headers['x-subject-token']\n",
    "    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n",
    "    resp2 = requests.get(url=url2, headers=headers2)\n",
    "    return json.loads(resp2.content)\n",
    "\n",
    "\n",
    "# loading the imdb movie data\n",
    "\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# @hidden_cell\n",
    "# This function accesses a file in your Object Storage. The definition contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "def get_object_storage_file_with_credentials_3fd480833bbd4355a296f2558dc1b897(container, filename):\n",
    "    \"\"\"This functions returns a StringIO object containing\n",
    "    the file content from Bluemix Object Storage.\"\"\"\n",
    "\n",
    "    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n",
    "    data = {'auth': {'identity': {'methods': ['password'],\n",
    "            'password': {'user': {'name': 'member_b6c199f708035093454e23f2785a418ef096423b','domain': {'id': '1bfd0aa070764f39845124cf77d75a19'},\n",
    "            'password': 'VO~S.?)5E6g2!!Dh'}}}}}\n",
    "    headers1 = {'Content-Type': 'application/json'}\n",
    "    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n",
    "    resp1_body = resp1.json()\n",
    "    for e1 in resp1_body['token']['catalog']:\n",
    "        if(e1['type']=='object-store'):\n",
    "            for e2 in e1['endpoints']:\n",
    "                        if(e2['interface']=='public'and e2['region']=='dallas'):\n",
    "                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n",
    "    s_subject_token = resp1.headers['x-subject-token']\n",
    "    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n",
    "    resp2 = requests.get(url=url2, headers=headers2)\n",
    "    return StringIO(resp2.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the config file.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'username': u'root', u'edge_class': {u'acted_in': {u'out': {u'Linked_Class': u'person', u'Type': u'Link'}, u'in': {u'Linked_Class': u'movie', u'Type': u'Link'}}, u'worked_with': {u'out': {u'Linked_Class': u'person', u'Type': u'Link'}, u'in': {u'Linked_Class': u'person', u'Type': u'Link'}}}, u'Database_name': u'testdb', u'vertex_class': {u'person': {u'role': u'String', u'name': u'String', u'fblikes': u'Float'}, u'movie': {u'title': u'String', u'numCriticForReviews': u'Integer', u'imdbRating': u'Float', u'durationInMins': u'Integer', u'year': u'Integer', u'genre': u'String', u'movieFacebookLikes': u'Float', u'plotKeywords': u'String'}}, u'host': u'localhost', u'password': u'root', u'port': 2424}\n"
     ]
    }
   ],
   "source": [
    "node_data = get_data(credentials_1)\n",
    "print node_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the movie data.\n",
    "* There are many rows and columns in the data that are empty. Hence, It is important to clean the data. \n",
    "* All the empty rows and columns are dropped from the dataframe using `dropna()` function of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df= pd.read_csv(get_object_storage_file_with_credentials_3fd480833bbd4355a296f2558dc1b897('graphdb', 'INSIGHTS-GRAPHDB.csv'))\n",
    "imdb_df = imdb_df.dropna()\n",
    "imdb_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Connecting to Orientdb\n",
    "* Please use the 2424/node port for 2424 to access orientdb. The other port 2480/nodeport for 2480 is for orientdb studio.\n",
    "* You can refer to the readme of https://github.com/IBM/deploy-graph-db-container to find the ip-address of the kubernetes cluster and node port to which 2480 has been mapped.\n",
    "* Uncomment the first line of the next cell and Replace the content in the angular brackets and run this to connect to the orientdb that you have set up on kubernetes.\n",
    "`client = pyorient.OrientDB(<ip-address-of-the-kubernetes-cluster>,<node-port mapped to port 2424 of orientdb>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyorient.orient.OrientDB object at 0x7fb716756410>\n"
     ]
    }
   ],
   "source": [
    "#client = pyorient.OrientDB(<ip-address-of-the-kubernetes-cluster>,<node-port mapped to port 2424 of orientdb>)\n",
    "\n",
    "print(client)\n",
    "\n",
    "### session-id username and password is global paswword, you have set for orientdb\n",
    "session_id = client.connect(node_data['username'], node_data['password'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some handy functions used in the notebook.\n",
    "#### verifying functions to avoid duplicacy errors!\n",
    "*  method to check if class is present or not \n",
    "*  method to check if a person is present or not \n",
    "*  method to check if a movie is present or not \n",
    "#### To get information of a class\n",
    "*  method to find the cluster of a class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to check if class is present or not \n",
    "def check_if_class_present_or_not(classname):\n",
    "    name=\"will be replaced by query result name\"\n",
    "    query = \"SELECT FROM ( SELECT expand( classes ) FROM metadata:schema ) WHERE name = \" +'\"'+ classname + '\"'\n",
    "    print(query)\n",
    "    a = client.command(query)\n",
    "    \n",
    "    for k in a:\n",
    "        name = k.name\n",
    "    \n",
    "    if(name == classname):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# method to check if a person is present or not     \n",
    "def check_if_already_present():\n",
    "    check_if_already_present = \"select * from person\"\n",
    "    c = client.command(check_if_already_present)\n",
    "    d=[]\n",
    "\n",
    "    for name in c:\n",
    "        d.append([name.name, name.role, name.fblikes])\n",
    "\n",
    "\n",
    "    check_df = pd.DataFrame(list(d), columns=['name','role','fblikes'])\n",
    "    return check_df\n",
    "\n",
    "\n",
    "# method to check if a movie is present or not \n",
    "def check_if_already_present_movie():\n",
    "    check_if_already_present = \"select title , year from movie\"\n",
    "    c = client.command(check_if_already_present)\n",
    "  \n",
    "    d=[]\n",
    "\n",
    "    for name in c:\n",
    "        d.append([name.title, name.year])\n",
    "\n",
    "\n",
    "    check_df_movie = pd.DataFrame(list(d), columns=['title','year'])\n",
    "    return check_df_movie\n",
    "\n",
    "## method to find the cluster of a class \n",
    "def find_the_Cluster_id_of_a_class (classname):\n",
    "    find_the_Cluster_id_of_a_class = \"SELECT defaultClusterId from (SELECT expand( classes ) FROM metadata:schema) where name = '\" + classname + \"'\"\n",
    "    print(find_the_Cluster_id_of_a_class)\n",
    "    c = client.command(find_the_Cluster_id_of_a_class)\n",
    "    for ids in c:\n",
    "        return ids.defaultClusterId\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new database!\n",
    "* Method for creating Database : createDatabase() : takes node_data as argument. This method checks if database you want to create is already present  \n",
    "\n",
    "#### Creating Node(vertex) class\n",
    "* There will be two vertex classes namely - Person and Movie.With Person’s attribute as Role: Director/Actor, Name, Fb-likes; Movie’s Attributes as Title, Year, IMDB, rating, Duration, Language, Genre, Plot, keywords, Num_critic_for_reviews, movie_facebook_likes.command to create the edge class: `create class <classname> extends V`.\n",
    "* There are two methods : \n",
    "    * createNodeClass_withSchema() : use this method when the user knows the properties of a node class. \n",
    "    * createNodeClass_NoSchema() :   use this method when the user doesn't knows the properties of a node class.\n",
    "* As in the config file, The schema has been defined for the person class and edge class.Function createNodeClass_withSchema() has been used.However, the user can use the other function when they don't have defined schema.\n",
    "\n",
    "#### Creating Relations(Edge) class\n",
    "* In Graph databases, a relation is the connection between two nodes, which in OrientDB is called an edge. Edges are bidirectional and can only connect two vertices. With the Graph API, Edges connect only two vertices.This means that 1:n relationships are not allowed. To specify a 1:n relationship with graphs, create multiple edges.command to create the edge class: `create class <classname> extends E`.\n",
    "\n",
    "* The method used is :\n",
    "    * createEdgeClass() : Edges have two ends.It always start from one vertex class and ends on another vertex.Its acts as a bridge between two vertices.Hence, The edge will always have in and out property. To create these properties of the Edge class, the commands are \n",
    "    `Create property <class-name>.in IF NOT EXISTS Link <linked_vertex_class>`\n",
    "    `Create property <class-name>.out IF NOT EXISTS Link <linked_vertex_class>`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Method for creating Database\n",
    "def createDatabase(node_data):\n",
    "    # check if it exists or not\n",
    "    if client.db_exists( node_data['Database_name'], pyorient.STORAGE_TYPE_MEMORY ):\n",
    "        client.db_open(node_data['Database_name'],node_data['username'], node_data['password'])\n",
    "        print node_data['Database_name'] + \" \"+ \"has already been created and opened for use\"\n",
    "    else:\n",
    "    # create the database\n",
    "        client.db_create( node_data['Database_name'], pyorient.DB_TYPE_GRAPH, pyorient.STORAGE_TYPE_MEMORY )\n",
    "        print node_data['Database_name'] + \" created and opened successfully\"\n",
    "        \n",
    "\n",
    "# Method for createNodeClass_withSchema\n",
    "def createNodeClass_withSchema(node_data):\n",
    "    for class_name,value in node_data['vertex_class'].items():\n",
    "        bool_result = check_if_class_present_or_not(class_name)\n",
    "        print bool_result\n",
    "        if(not bool_result):\n",
    "            command_to_create_node = \"create class\"+\" \"+ class_name +\" \"+ \"extends V\"\n",
    "            print(command_to_create_node)\n",
    "            cluster_id = client.command(command_to_create_node) \n",
    "            print class_name,cluster_id\n",
    "            for property_name,value in node_data['vertex_class'][class_name].items():\n",
    "                ### create properties \n",
    "                command_to_create_property= \"create property\"+ \" \"+ class_name +\".\" + property_name +\" \" +\"IF NOT EXISTS \" + value\n",
    "                print(command_to_create_property)\n",
    "                client.command(command_to_create_property) \n",
    "            print \"class \" + class_name + \" and its properties successfully created\"\n",
    "        else:\n",
    "            print \"this class is already present !!\"\n",
    "\n",
    "# method for creating createNodeClass_NoSchema.\n",
    "def createNodeClass_NoSchema(node_data):\n",
    "    for class_name,value in node_data['vertex_class'].items():\n",
    "        if(check_if_class_present_or_not(class_name)):\n",
    "            command_to_create_node = \"create class\"+\" \"+ class_name +\" \"+ \"extends V\"\n",
    "            print(command_to_create_node)\n",
    "            cluster_id = client.command(command_to_create_node) \n",
    "            print class_name + \" has been created with cluster id \" +cluster_id\n",
    "        else:\n",
    "            print \"this class is already present !!\"\n",
    "            \n",
    "# method for creating edge class.\n",
    "def createEdgeClass(node_data):\n",
    "    for class_name,v in node_data['edge_class'].items():\n",
    "        if(not check_if_class_present_or_not(class_name)):\n",
    "            command_to_create_edge_class = \"create class\"+\" \"+ class_name +\" \"+ \"extends E\"\n",
    "            print(command_to_create_edge_class)\n",
    "            cluster_id = client.command(command_to_create_edge_class)\n",
    "            print(\"Edge class\" +\" \" + class_name + \"has been created successfully!\")\n",
    "\n",
    "            for key,val in node_data['edge_class'][class_name].items():\n",
    "                print key,val\n",
    "                command_to_create_property= \"create property\"+ \" \"+ class_name +\".\" + key +\" \" +\"IF NOT EXISTS \" + node_data['edge_class'][class_name][key]['Type']+\" \" + node_data['edge_class'][class_name][key]['Linked_Class']\n",
    "                print(command_to_create_property)\n",
    "                client.command(command_to_create_property) \n",
    "                print node_data['edge_class'][class_name][key]['Type'], node_data['edge_class'][class_name][key]['Linked_Class']\n",
    "        else:\n",
    "             print \"this class is already present !!\"\n",
    "            \n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDatabase(node_data)\n",
    "createNodeClass_withSchema(node_data)\n",
    "#createNodeClass_NoSchema(node_data)\n",
    "createEdgeClass(node_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating nodes and edges between them.\n",
    "\n",
    "#### creating nodes\n",
    "* Before inserting any record for person or movie, it is checked that if its already present or not using     check_if_already_present().\n",
    "* check_if_already_present() -- function returns the dataframe with the records of person class already present in the database.\n",
    "* check_if_already_present_movie() -- function returns the dataframe with the records of a movie class already present in the database.\n",
    "\n",
    "#### creating relations\n",
    "* check if both the nodes are present in the records before creating an edge between them.\n",
    "* In this person to person relation has been created with `worked_with` class and person to movie has been created with `acted_in`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to create the edge and the link when you have designed schema for your graphdb\n",
    "def creating_records(imdb_df):\n",
    "    for index, row in imdb_df.iterrows():\n",
    "        ''' creating records -- all three actors and director \n",
    "        '''\n",
    "        check_df = check_if_already_present()\n",
    "        if(any(check_df.name == row[\"actor_1_name\"])):\n",
    "            print \"node \"+row[\"actor_1_name\"] +\" is already present!!\"\n",
    "        else:\n",
    "            command_to_create_actor_1_node_class_person  = \"INSERT INTO person (name, fblikes, role) VALUES (\" +'\"' +row[\"actor_1_name\"]+'\"' + ','+ str(row[\"actor_1_facebook_likes\"])+',' +'\"' +'actor'+'\"' + \")\"\n",
    "            client.command(command_to_create_actor_1_node_class_person)\n",
    "            print \"node \"+row[\"actor_1_name\"] +\" has been created!!\"\n",
    "            \n",
    "        if(any(check_df.name == row[\"actor_2_name\"])):\n",
    "            print \"node \"+row[\"actor_2_name\"] +\" is already present!!\"\n",
    "        else:\n",
    "            command_to_create_actor_2_node_class_person  = \"INSERT INTO person (name, fblikes, role) VALUES (\" +'\"' +row[\"actor_2_name\"]+'\"' + ','+ str(row[\"actor_2_facebook_likes\"])+',' +'\"' +'actor'+'\"' + \")\"\n",
    "            client.command(command_to_create_actor_2_node_class_person)\n",
    "            print \"node \"+row[\"actor_2_name\"] +\" has been created!!\"\n",
    "            \n",
    "        if(any(check_df.name == row[\"actor_3_name\"])):\n",
    "            print \"node \"+row[\"actor_3_name\"] +\" is already present!!\"\n",
    "        else:\n",
    "            command_to_create_actor_3_node_class_person  = \"INSERT INTO person (name, fblikes, role) VALUES (\" +'\"' +row[\"actor_3_name\"]+'\"' + ','+ str(row[\"actor_3_facebook_likes\"])+',' +'\"' +'actor'+'\"' + \")\"\n",
    "            client.command(command_to_create_actor_3_node_class_person)\n",
    "            print \"node \"+row[\"actor_3_name\"] +\" has been created!!\"\n",
    "            \n",
    "        if(any(check_df.name == row[\"director_name\"])):\n",
    "            print \"node \"+row[\"director_name\"] +\" is already present!!\"\n",
    "        else:\n",
    "            command_to_create_director_node_class_person  = \"INSERT INTO person (name, fblikes, role) VALUES (\" +'\"' +row[\"director_name\"]+'\"' + ','+ str(row[\"director_facebook_likes\"])+',' +'\"' +'director'+'\"' + \")\"\n",
    "            client.command(command_to_create_director_node_class_person)\n",
    "            print \"node \"+row[\"director_name\"] +\" has been created!!\"\n",
    "        \n",
    "        command_to_create_movie  = \"INSERT INTO movie (title, year, durationInMins, imdbRating, genre, plotKeywords, numCriticForReviews, movieFacebookLikes) VALUES (\" +'\"' +row[\"movie_title\"]+'\"' + ','+ str(row[\"title_year\"])+','+str(row[\"duration\"])+','+str(row[\"imdb_score\"])+',' +'\"'+row[\"genres\"]+'\"' +','+'\"' +row[\"plot_keywords\"]+'\"'+','+str(row[\"num_critic_for_reviews\"])+','+str(row[\"movie_facebook_likes\"])+\")\"\n",
    "        print command_to_create_movie\n",
    "        client.command(command_to_create_movie)\n",
    "        print \"node \"+row[\"movie_title\"] +\" has been created!!\"\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "def createRelationships():\n",
    "      for index, row in imdb_df.iterrows():\n",
    "            '''create_edge_between_two_actors_1 and actor_2 \n",
    "            '''\n",
    "            if((row[\"actor_1_name\"]  in check_df.name.values) and (row[\"actor_2_name\"]  in check_df.name.values)):\n",
    "                command_to_create_edge_between_two_actors_1_and_2 = \"create edge worked_with from (select from person where name = \"+'\"'+row[\"actor_1_name\"]+'\"'+ \")\"+\" \" +\"to (select from person where name = \"+'\"'+row[\"actor_2_name\"]+'\"'+\")\"\n",
    "                print(command_to_create_edge_between_two_actors_1_and_2)\n",
    "                client.command(command_to_create_edge_between_two_actors_1_and_2)\n",
    "                print \"edge has been created successfully!\"\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "            \n",
    "            \n",
    "            '''create_edge_between_two_actors_1 and actor_2 \n",
    "            '''\n",
    "            if((row[\"actor_2_name\"]  in check_df.name.values) and  (row[\"actor_3_name\"]  in check_df.name.values) ):\n",
    "                command_to_create_edge_between_two_actors_2_and_3 = \"create edge worked_with from (select from person where name = \"+'\"'+row[\"actor_2_name\"]+'\"'+ \")\"+\" \" +\"to (select from person where name = \"+'\"'+row[\"actor_3_name\"]+'\"'+\")\"\n",
    "                print(command_to_create_edge_between_two_actors_2_and_3)\n",
    "                client.command(command_to_create_edge_between_two_actors_2_and_3)\n",
    "                print \"edge has been created successfully!\"\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "               \n",
    "\n",
    "            '''create_edge_between_two_actors_1 and actor_2\n",
    "            '''\n",
    "            if((row[\"actor_2_name\"]  in check_df.name.values) and ( row[\"actor_3_name\"]  in check_df.name.values )):\n",
    "                command_to_create_edge_between_two_actors_3_and_1 = \"create edge worked_with from (select from person where name = \"+'\"'+row[\"actor_3_name\"]+'\"'+ \")\"+\" \" +\"to (select from person where name = \"+'\"'+row[\"actor_1_name\"]+'\"'+\")\"\n",
    "                print(command_to_create_edge_between_two_actors_3_and_1)\n",
    "                client.command(command_to_create_edge_between_two_actors_3_and_1)\n",
    "                print \"edge has been created successfully!\"\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "                \n",
    "            '''create_edge_between actor_1 and director \n",
    "            '''\n",
    "            if((row[\"actor_1_name\"]  in check_df.name.values) and  (row[\"director_name\"] in check_df.name.values) ):\n",
    "                command_to_create_edge_between_actor_1_and_director = \"create edge worked_with from (select from person where name = \"+'\"'+row[\"director_name\"]+'\"'+ \")\"+\" \" +\"to (select from person where name = \"+'\"'+row[\"actor_1_name\"]+'\"'+\")\"\n",
    "                print(command_to_create_edge_between_actor_1_and_director)\n",
    "                client.command(command_to_create_edge_between_actor_1_and_director)\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "\n",
    "            '''create_edge_between actor_2 and director\n",
    "            '''\n",
    "            if((row[\"actor_2_name\"]  in check_df.name.values) and ( row[\"director_name\"] in check_df.name.values) ):\n",
    "                command_to_create_edge_between_actor_2_and_director = \"create edge worked_with from (select from person where name = \"+'\"'+row[\"director_name\"]+'\"'+ \")\"+\" \" +\"to (select from person where name = \"+'\"'+row[\"actor_2_name\"]+'\"'+\")\"\n",
    "                print(command_to_create_edge_between_actor_2_and_director)\n",
    "                client.command(command_to_create_edge_between_actor_2_and_director)\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "            \n",
    "            '''create_edge_between actor_3 and director \n",
    "            '''\n",
    "            if((row[\"actor_3_name\"]  in check_df.name.values) and ( row[\"director_name\"] in check_df.name.values) ):\n",
    "                command_to_create_edge_between_actor_3_director = \"create edge worked_with from (select from person where name = \"+'\"'+row[\"director_name\"]+'\"'+ \")\"+\" \" +\"to (select from person where name = \"+'\"'+row[\"actor_3_name\"]+'\"'+\")\"\n",
    "                print(command_to_create_edge_between_actor_3_director)\n",
    "                client.command(command_to_create_edge_between_actor_3_director)\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "\n",
    "            '''movies and actors \n",
    "            '''\n",
    "            '''create_edge_between_actors_1_and_movie\n",
    "            '''\n",
    "            if((row[\"actor_1_name\"]  in check_df.name.values) and  (row[\"movie_title\"] in check_df_movie.title.values)):\n",
    "                command_to_create_edge_between_actors_1_and_movie = \"create edge acted_in from (select from person where name = \"+'\"'+row[\"actor_1_name\"]+'\"'+ \")\"+\" \" +\"to (select from movie where title = \"+'\"'+row[\"movie_title\"]+'\"'+\")\"\n",
    "                print(command_to_create_edge_between_actors_1_and_movie)\n",
    "                client.command(command_to_create_edge_between_actors_1_and_movie)\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "\n",
    "            '''create_edge_between_actors_2_and_movie\n",
    "            '''\n",
    "            if((row[\"actor_2_name\"]  in check_df.name.values) and  (row[\"movie_title\"] in check_df_movie.title.values) ):\n",
    "                command_to_create_edge_between_actors_2_and_movie = \"create edge acted_in from (select from person where name = \"+'\"'+row[\"actor_2_name\"]+'\"'+ \")\"+\" \" +\"to (select from movie where title = \"+'\"'+row[\"movie_title\"]+'\"'+\")\"\n",
    "                print( command_to_create_edge_between_actors_2_and_movie )\n",
    "                client.command(command_to_create_edge_between_actors_2_and_movie)\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "            \n",
    "            '''create_edge_between_actors_3_and_movie \n",
    "            '''\n",
    "            if((row[\"actor_3_name\"]  in check_df.name.values) and  (row[\"movie_title\"] in check_df_movie.title.values)):\n",
    "                command_to_create_edge_between_actors_3_and_movie = \"create edge acted_in from (select from person where name = \"+'\"'+row[\"actor_3_name\"]+'\"'+ \")\"+\" \" +\"to (select from movie where title= \"+'\"'+row[\"movie_title\"]+'\"'+\")\"\n",
    "                print(command_to_create_edge_between_actors_3_and_movie)\n",
    "                client.command(command_to_create_edge_between_actors_3_and_movie)\n",
    "            else:\n",
    "                   print \"edge cant be created because vertext is not present !!!!!\"\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "creating_records(imdb_df)\n",
    "check_df = check_if_already_present()\n",
    "check_df_movie = check_if_already_present_movie()\n",
    "createRelationships()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The orientdb provides flexible schema as it is a nosql and sql database.\n",
    "* To create a record using json.\n",
    "    * use this function of pyorient : \n",
    "        ` client.record_create(<cluster_id>, <data>)`\n",
    "        `Data should be in json format. `\n",
    "\n",
    "\n",
    "`Note that a  new property  \"born_in\" which is not defined in schema, has been added in the json.You can add as many number of attributes in the json for a particular record. The record with stored as json.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT defaultClusterId from (SELECT expand( classes ) FROM metadata:schema) where name = 'person'\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "        'person': {\n",
    "                \"name\": \"John\", \n",
    "                \"role\": \"director\",\n",
    "                \"fblikes\": 400000.0,\n",
    "                \"born_in\" : 1980\n",
    "                },\n",
    "        }\n",
    "\n",
    "for key, value in data.iteritems():\n",
    "        cluster_id = find_the_Cluster_id_of_a_class(key)\n",
    "        print cluster_id\n",
    "\n",
    "def creating_records_noschema(data):\n",
    "        id = client.record_create(cluster_id, data)\n",
    "        print \"record succesfully created with \" + str(id)\n",
    "        \n",
    "creating_records_noschema(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Mentioned\n",
    "Movie with maximum no of facebook likes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#most mentioned \n",
    "def most_mentioned_movie():\n",
    "    a = client.command(('select max(movieFacebookLikes) from movie '))\n",
    "\n",
    "    for max_num in a :\n",
    "        max_num = max_num.max\n",
    "    print max_num\n",
    "    most_mentioned_movie_object = client.command('select title from movie where movieFacebookLikes = ' + str(max_num))\n",
    "    \n",
    "    for titles in most_mentioned_movie_object :\n",
    "        print titles.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349000\n",
      "InterstellarÂ\n"
     ]
    }
   ],
   "source": [
    "most_mentioned_movie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering \n",
    "\n",
    "Cluster movies with rating above 7.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_with_imdb_rating_above_7():\n",
    "    title = []\n",
    "    a = client.command(('select title from movie where imdbRating > 7 '))\n",
    "    for titles in a :\n",
    "        title.append(titles.title)\n",
    "    title_df = pd.DataFrame(list(title), columns=['title'])    \n",
    "    return title_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_with_imdb_rating_above_7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 1.6",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
